{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final code for capturing discriminative features to be written here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all file in this block\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from pprint import pprint\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readDataFiles : reads the file and return list of list of words, and label if necessary\n",
    "#path_var: variable for path of file to be read, mode: type of data(test - 1 or trian - 0)\n",
    "def readDataFiles(path_var, mode):\n",
    "    data = []\n",
    "    label = []\n",
    "    with open(path_var , 'r') as file_obj:\n",
    "        for line in file_obj:\n",
    "            temp = line.split(',')\n",
    "            data.append(temp[:3])\n",
    "            if(1 != mode):\n",
    "                label.append(temp[-1][0])\n",
    "    if(1 != mode):\n",
    "        return data, label\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generateModel : generates the word2vec model for the data gathered\n",
    "def generateModel(train_set, val_set, test_set):\n",
    "    word_set = train_set + val_set + test_set\n",
    "    word_model = gensim.models.Word2Vec(word_set, min_count = 1, size = 30, window = 5)\n",
    "    return word_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def main():\n",
    "    \n",
    "    #setting of path to take data\n",
    "    train_path = \"./training/train.txt\"\n",
    "    val_path = \"./training/validation.txt\"\n",
    "    test_path = \"./test/test_triples.txt\"\n",
    "    \n",
    "    #reading data from the respective files\n",
    "    train_set, label_train = readDataFiles(train_path, 0)\n",
    "    val_set, label_val = readDataFiles(val_path, 0)\n",
    "    test_set = readDataFiles(test_path, 1)\n",
    "    \n",
    "    #generating word2vec model for the data\n",
    "    word_model = generateModel(train_set, val_set, test_set)\n",
    "    print(word_model['duck'])\n",
    "    print(word_model['goose'])\n",
    "    print(word_model['banjo'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23612145  0.14229438  0.04611893 -0.14961274  0.22379719 -0.03821951\n",
      "  0.8071743   0.10653729  0.7034845  -0.3558253   0.5386692   0.17328683\n",
      "  0.11150075  0.27465928 -0.5621172   0.07859766  0.20114858  0.93067133\n",
      "  0.3436739   0.09713548 -0.00462596  0.7760741  -0.55704606 -0.7184987\n",
      " -0.20876855 -0.19324303  0.18716839 -0.57403165 -0.73104644 -0.40100437]\n",
      "[-0.24028137  0.11217402  0.03559578 -0.1673202   0.22046518 -0.02201751\n",
      "  0.6895589   0.10080764  0.6065974  -0.32800788  0.44108763  0.11930235\n",
      "  0.08292683  0.23841794 -0.47257602  0.07969161  0.18832669  0.7859786\n",
      "  0.27304676  0.11110046 -0.00596492  0.6365229  -0.47858575 -0.6258688\n",
      " -0.15331475 -0.12853031  0.15187573 -0.44523227 -0.64697903 -0.33599994]\n",
      "[-0.25791427  0.16552447  0.04338381 -0.155059    0.17055428 -0.05610887\n",
      "  0.6093836   0.07132014  0.5853008  -0.29375628  0.39055645  0.07272342\n",
      "  0.02919177  0.19814578 -0.44042978  0.0685562   0.19062765  0.7412731\n",
      "  0.30067056  0.04479971  0.01069023  0.6517344  -0.43651417 -0.5660309\n",
      " -0.0832536  -0.07047571  0.1567355  -0.44931963 -0.56552136 -0.21216843]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
