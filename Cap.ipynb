{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final code for capturing discriminative features to be written here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all file in this block\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from pprint import pprint\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#tests\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readDataFiles : reads the file and return list of list of words, and label if necessary\n",
    "#path_var: variable for path of file to be read, mode: type of data(test - 1 or trian - 0)\n",
    "def readDataFiles(path_var, mode):\n",
    "    data = []\n",
    "    label = []\n",
    "    with open(path_var , 'r') as file_obj:\n",
    "        for line in file_obj:\n",
    "            temp = line.split(',')\n",
    "            data.append(temp[:3])\n",
    "            if(1 != mode):\n",
    "                label.append(temp[-1][0]) #temp[-1][0] since the label is using single digit for representation\n",
    "    if(1 != mode):\n",
    "        return data, label\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generateModel : generates the word2vec model for the data gathered\n",
    "def generateModel(train_set, val_set, test_set):\n",
    "    word_set = train_set + val_set + test_set\n",
    "    word_model = gensim.models.Word2Vec(word_set, min_count = 1, size = 30, window = 5)\n",
    "    return word_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEucledianDistanceVector(data, word_model, fv_size):\n",
    "    n = len(data)\n",
    "    X = np.matrix(np.zeros((n, fv_size)))\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        v = np.zeros(fv_size)\n",
    "        v[0] = np.linalg.norm(word_model[data[i][0]]-word_model[data[i][2]])\n",
    "        v[1] = np.linalg.norm(word_model[data[i][1]]-word_model[data[i][2]])\n",
    "#        print(v[0],v[1])\n",
    "        X[i, : ] = v\n",
    "#        print (\"   \", X[i])\n",
    "        i += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineVector(data, word_model, fv_size):\n",
    "    n = len(data)\n",
    "    X = np.matrix(np.zeros((n, fv_size)))\n",
    "#    print(X.shape)\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        v = np.zeros(fv_size)\n",
    "        v[0] = word_model.similarity(data[i][0], data[i][2])\n",
    "        v[1] = word_model.similarity(data[i][1], data[i][2])\n",
    "#        print(v[0],v[1])\n",
    "        X[i, : ] = v\n",
    "#        print (\"   \", X[i])\n",
    "        i += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class 0 is represented by index 0 and 1 by index 1 in rows of Y matrix \n",
    "def getClassVector(data, no_class):\n",
    "    n = len(data)\n",
    "    Y = np.matrix(np.zeros((n, no_class)))\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        Y[i, int(data[i])] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(train_X, train_Y, epochs, learning_rate):\n",
    "    size, m = train_X.shape\n",
    "    train_X = np.hstack((train_X, np.ones((size, 1))))\n",
    "    m, n = (train_X.shape[1], train_Y.shape[1])\n",
    "    w = np.random.rand(m, n)\n",
    "    w = w / 1000\n",
    "    for epoch in range(epochs):\n",
    "        print (epoch, end = \" \")\n",
    "        for index in range(size):\n",
    "            inp = train_X[index]\n",
    "            target = train_Y[index]\n",
    "            op = np.matmul(inp, w)\n",
    "            op = sigmoid(op)\n",
    "            diff = op - target\n",
    "            update = np.matmul(inp.T, diff)\n",
    "            w = w - learning_rate * update\n",
    "    print()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpClassifier(train_X, train_Y, epochs, lr):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, learning_rate='constant', learning_rate_init=lr ,max_iter=epochs)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_tag(target):\n",
    "    return np.argmax(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, train_Y, model, epochs, learning_rate):\n",
    "    if(0 == model):\n",
    "        w = logisticRegression(train_X, train_Y, epochs, learning_rate)\n",
    "    elif(1==model):\n",
    "        l = len(train_Y)\n",
    "        Y = np.zeros(l)\n",
    "        i = 0\n",
    "        for i in range(l):\n",
    "            Y[i] = correct_tag(train_Y[i])\n",
    "        w = mlpClassifier(train_X, Y, epochs, learning_rate)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inp , w):\n",
    "    op = np.matmul(inp, w)\n",
    "    return np.argmax(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(data_X, data_Y, w, model):\n",
    "    TP=0\n",
    "    TOT = 0\n",
    "    size = len(data_X)\n",
    "    if(0==model):\n",
    "        for index in range(size):\n",
    "            inp = np.matrix(np.hstack((data_X[index], np.ones((1, 1)))))\n",
    "            target = data_Y[index]\n",
    "            if(1 == correct_tag(target)):\n",
    "                TOT+=1\n",
    "                if(1 == predict(inp,w)):\n",
    "                    TP+=1\n",
    "    elif(1==model):\n",
    "        pr = w.predict(data_X)\n",
    "        for index in range(size):\n",
    "            target = data_Y[index]\n",
    "            if(1 == correct_tag(target)):\n",
    "                TOT+=1\n",
    "                if(1 == pr[index]):\n",
    "                    TP +=1\n",
    "    return TP/TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(data_X, data_Y, w, model):\n",
    "    TP=0\n",
    "    TOT = 0\n",
    "    size = len(data_X)\n",
    "    if(0==model):\n",
    "        for index in range(size):\n",
    "            inp = np.matrix(np.hstack((data_X[index], np.ones((1, 1)))))\n",
    "            target = data_Y[index]\n",
    "            if(1 == predict(inp,w)):\n",
    "                TOT += 1\n",
    "                if(1 == correct_tag(target)):\n",
    "                    TP +=1\n",
    "    elif(1==model):\n",
    "        pr = w.predict(data_X)\n",
    "        for index in range(size):\n",
    "            target = data_Y[index]\n",
    "            if(1==pr[index]):\n",
    "                TOT += 1\n",
    "                if(1 == correct_tag(target)):\n",
    "                    TP +=1\n",
    "    return TP/TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data_X, data_Y, w, model):\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    size = len(data_X)\n",
    "    if (0==model):\n",
    "        for index in range(size):\n",
    "            inp = np.matrix(np.hstack((data_X[index], np.ones((1, 1)))))\n",
    "            target = data_Y[index]\n",
    "            if predict(inp , w) == correct_tag(target):\n",
    "                correct += 1\n",
    "            i += 1\n",
    "    elif(1==model):\n",
    "        pr = w.predict(data_X)\n",
    "        for index in range(size):\n",
    "            target = data_Y[index]\n",
    "            if pr[i] == correct_tag(target):\n",
    "                correct += 1\n",
    "            i += 1\n",
    "    return (correct / i)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(prec,rec):\n",
    "    f = 2*prec*rec\n",
    "    f = f/(prec+rec)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def main():\n",
    "    \n",
    "    #setting of path to take data\n",
    "    train_path = \"./training/train.txt\"\n",
    "    val_path = \"./training/validation.txt\"\n",
    "    test_path = \"./test/test_triples.txt\"\n",
    "    \n",
    "    #reading data from the respective files\n",
    "    train_set, label_train = readDataFiles(train_path, 0)\n",
    "    val_set, label_val = readDataFiles(val_path, 0)\n",
    "    test_set = readDataFiles(test_path, 1)\n",
    "    \n",
    "    #generating word2vec model for the data\n",
    "    word_model = generateModel(train_set, val_set, test_set)\n",
    "    \n",
    "#    print(word_model[train_set[0][0]])\n",
    "    \n",
    "#    return\n",
    "    #generating feature vector to use in the classifier. uses cosine similarity for feature vector\n",
    "    fv_size = 2\n",
    "    #train_X = getCosineVector(train_set, word_model, fv_size)\n",
    "    train_X = getEucledianDistanceVector(train_set, word_model, fv_size)\n",
    "    \n",
    "    #generating training label vectors depending on class\n",
    "    no_class = 2\n",
    "    train_Y = getClassVector(label_train, no_class)\n",
    "    \n",
    "    #training the model usning the vector consisting of cosine similarity values\n",
    "    model = 1  #0 means logistic regression and 1 means mlp\n",
    "    epochs = 100\n",
    "    learning_rate = 0.03\n",
    "    w = train(train_X, train_Y, model, epochs, learning_rate)\n",
    "#    pprint (w)\n",
    "    \n",
    "    #validating the weight_vector on val matrix\n",
    "    #val_X = getCosineVector(val_set, word_model, fv_size)\n",
    "    val_X = getEucledianDistanceVector(val_set, word_model, fv_size)\n",
    "    val_Y = getClassVector(label_val, no_class)\n",
    "#    aq = validate(val_X, val_Y, w, model)\n",
    "#    print(aq)\n",
    "#    pr = w.predict(val_X)\n",
    "#    print(pr)\n",
    "#    pprint(val_Y)\n",
    "#    aq = validate(val_V,val_Y,w,model)\n",
    "    acc = accuracy(val_X, val_Y, w, model)\n",
    "    print(\"accuracy\\t=\\t\", acc,\"%\")\n",
    "    prec = precision(val_X, val_Y, w, model)\n",
    "    print(\"precision\\t=\\t\",prec)\n",
    "    rec = recall(val_X, val_Y, w, model)\n",
    "    print(\"recall\\t\\t=\\t\",rec)\n",
    "    f1 = f1_score(prec,rec)\n",
    "    print(\"f1_score\\t=\\t\",f1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t=\t 48.163115356355625 %\n",
      "precision\t=\t 0.4899615548910722\n",
      "recall\t\t=\t 0.8409090909090909\n",
      "f1_score\t=\t 0.6191632928475034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
