{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final code for capturing discriminative features to be written here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all file in this block\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from pprint import pprint\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readDataFiles : reads the file and return list of list of words, and label if necessary\n",
    "#path_var: variable for path of file to be read, mode: type of data(test - 1 or trian - 0)\n",
    "def readDataFiles(path_var, mode):\n",
    "    data = []\n",
    "    label = []\n",
    "    with open(path_var , 'r') as file_obj:\n",
    "        for line in file_obj:\n",
    "            temp = line.split(',')\n",
    "            data.append(temp[:3])\n",
    "            if(1 != mode):\n",
    "                label.append(temp[-1][0]) #temp[-1][0] since the label is using single digit for representation\n",
    "    if(1 != mode):\n",
    "        return data, label\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generateModel : generates the word2vec model for the data gathered\n",
    "def generateModel(train_set, val_set, test_set):\n",
    "    word_set = train_set + val_set + test_set\n",
    "    word_model = gensim.models.Word2Vec(word_set, min_count = 1, size = 30, window = 5)\n",
    "    return word_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineVector(data, word_model, fv_size):\n",
    "    n = len(data)\n",
    "    X = np.matrix(np.zeros((n, fv_size)))\n",
    "#    print(X.shape)\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        v = np.zeros(fv_size)\n",
    "        v[0] = word_model.similarity(data[i][0], data[i][2])\n",
    "        v[1] = word_model.similarity(data[i][1], data[i][2])\n",
    "#        print(v[0],v[1])\n",
    "        X[i, : ] = v\n",
    "#        print (\"   \", X[i])\n",
    "        i += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class 0 is represented by index 0 and 1 by index 1 in rows of Y matrix \n",
    "def getClassVector(data, no_class):\n",
    "    n = len(data)\n",
    "    Y = np.matrix(np.zeros((n, no_class)))\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        Y[i, int(data[i])] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(train_X, train_Y, epochs, learning_rate):\n",
    "    size, m = train_X.shape\n",
    "    train_X = np.hstack((train_X, np.ones((size, 1))))\n",
    "    m, n = (train_X.shape[1], train_Y.shape[1])\n",
    "    w = np.random.rand(m, n)\n",
    "    w = w / 1000\n",
    "    for epoch in range(epochs):\n",
    "        print (epoch, end = \" \")\n",
    "        for index in range(size):\n",
    "            inp = train_X[index]\n",
    "            target = train_Y[index]\n",
    "            op = np.matmul(inp, w)\n",
    "            op = sigmoid(op)\n",
    "            diff = op - target\n",
    "            update = np.matmul(inp.T, diff)\n",
    "            w = w - learning_rate * update\n",
    "    print()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, train_Y, model, epochs, learning_rate):\n",
    "    if(0 == model):\n",
    "        w = logisticRegression(train_X, train_Y, epochs, learning_rate)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inp , w):\n",
    "    op = np.matmul(inp, w)\n",
    "    return np.argmax(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_tag(target):\n",
    "    return np.argmax(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_X, data_Y, w):\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    size = len(data_X)\n",
    "    for index in range(size):\n",
    "        inp = np.matrix(np.hstack((data_X[index], np.ones((1, 1)))))\n",
    "        target = data_Y[index]\n",
    "        if predict(inp , w) == correct_tag(target):\n",
    "            correct += 1\n",
    "        i += 1\n",
    "    return (correct / i)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def main():\n",
    "    \n",
    "    #setting of path to take data\n",
    "    train_path = \"./training/train.txt\"\n",
    "    val_path = \"./training/validation.txt\"\n",
    "    test_path = \"./test/test_triples.txt\"\n",
    "    \n",
    "    #reading data from the respective files\n",
    "    train_set, label_train = readDataFiles(train_path, 0)\n",
    "    val_set, label_val = readDataFiles(val_path, 0)\n",
    "    test_set = readDataFiles(test_path, 1)\n",
    "    \n",
    "    #generating word2vec model for the data\n",
    "    word_model = generateModel(train_set, val_set, test_set)\n",
    "    \n",
    "    #generating feature vector to use in the classifier. uses cosine similarity for feature vector\n",
    "    fv_size = 2\n",
    "    train_X = getCosineVector(train_set, word_model, fv_size)\n",
    "    \n",
    "    #generating training label vectors depending on class\n",
    "    no_class = 2\n",
    "    train_Y = getClassVector(label_train, no_class)\n",
    "    \n",
    "    #training the model usning the vector consisting of cosine similarity values\n",
    "    model = 0  #0 means logistic regression and 1 means naive bayes\n",
    "    epochs = 100\n",
    "    learning_rate = 0.03\n",
    "    w = train(train_X, train_Y, model, epochs, learning_rate)\n",
    "    pprint (w)\n",
    "    \n",
    "    #validating the weight_vector on val matrix\n",
    "    val_X = getCosineVector(val_set, word_model, fv_size)\n",
    "    val_Y = getClassVector(label_val, no_class)\n",
    "    aq = validate(val_X, val_Y, w)\n",
    "    print(aq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
